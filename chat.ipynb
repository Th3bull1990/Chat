{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5743ce8aaebe45aab53e99dea398c13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPTNeoXForCausalLM, AutoConfig\n",
    "from accelerate import init_empty_weights\n",
    "import json \n",
    "\n",
    "# with open('device_map.json', 'r') as f:\n",
    "#     device_map = json.load(f)\n",
    "    \n",
    "checkpoint = \"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\"\n",
    "cache_dir='cache'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=cache_dir)\n",
    "# model = GPTNeoXForCausalLM.from_pretrained(checkpoint, cache_dir=cache_dir).half().cuda()\n",
    "# model = GPTNeoXForCausalLM.from_pretrained(checkpoint, cache_dir=cache_dir, device_map=device_map)#.half()\n",
    "model = GPTNeoXForCausalLM.from_pretrained(checkpoint, cache_dir=cache_dir, device_map=\"auto\").half()\n",
    "# model.tie_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt_neox.embed_in': 0,\n",
       " 'gpt_neox.layers.0': 0,\n",
       " 'gpt_neox.layers.1': 0,\n",
       " 'gpt_neox.layers.2': 0,\n",
       " 'gpt_neox.layers.3': 0,\n",
       " 'gpt_neox.layers.4': 0,\n",
       " 'gpt_neox.layers.5': 0,\n",
       " 'gpt_neox.layers.6': 0,\n",
       " 'gpt_neox.layers.7': 0,\n",
       " 'gpt_neox.layers.8': 0,\n",
       " 'gpt_neox.layers.9': 0,\n",
       " 'gpt_neox.layers.10': 0,\n",
       " 'gpt_neox.layers.11': 0,\n",
       " 'gpt_neox.layers.12': 0,\n",
       " 'gpt_neox.layers.13': 0,\n",
       " 'gpt_neox.layers.14': 0,\n",
       " 'gpt_neox.layers.15': 0,\n",
       " 'gpt_neox.layers.16': 0,\n",
       " 'gpt_neox.layers.17': 1,\n",
       " 'gpt_neox.layers.18': 1,\n",
       " 'gpt_neox.layers.19': 1,\n",
       " 'gpt_neox.layers.20': 1,\n",
       " 'gpt_neox.layers.21': 1,\n",
       " 'gpt_neox.layers.22': 1,\n",
       " 'gpt_neox.layers.23': 1,\n",
       " 'gpt_neox.layers.24': 1,\n",
       " 'gpt_neox.layers.25': 1,\n",
       " 'gpt_neox.layers.26': 1,\n",
       " 'gpt_neox.layers.27': 1,\n",
       " 'gpt_neox.layers.28': 1,\n",
       " 'gpt_neox.layers.29': 1,\n",
       " 'gpt_neox.layers.30': 1,\n",
       " 'gpt_neox.layers.31': 1,\n",
       " 'gpt_neox.layers.32': 1,\n",
       " 'gpt_neox.layers.33': 1,\n",
       " 'gpt_neox.layers.34': 1,\n",
       " 'gpt_neox.layers.35': 1,\n",
       " 'gpt_neox.final_layer_norm': 1,\n",
       " 'embed_out': 'cpu'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json\n",
    "# import json \n",
    "# with open('device_map.json', 'w') as f:\n",
    "#     json.dump(model.hf_device_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is a meme, and what\\'s the history behind this word?A meme is a cultural element that spreads from person to person within a culture. The word \"meme\" was first used by Richard Dawkins in 1976, to describe a concept similar to what is now known as a virus. The word later came to refer to a joke, image, or piece of text that is spread to others via social media, email, or other digital means. The origin of the word is thought to be from the Greek word meaning \"to imitate.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"<|prompter|>What is a meme, and what's the history behind this word?<|endoftext|><|assistant|>\", return_tensors=\"pt\")\n",
    "inputs = inputs.to(0)\n",
    "tokens = model.generate(**inputs, do_sample=True, temperature=0.9, max_length=1024)\n",
    "tokenizer.decode(tokens[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
